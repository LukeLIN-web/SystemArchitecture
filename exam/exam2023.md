## 讲解





unrolling不是写代码的, 是编译器做的

除法很慢, 把除法展开快很多.







## **Question 1** 

Each request is guaranteed not to exceed 5msec in processing time.

 a request’s response time cannot exceed 10 msec.

Web requests arrive at random according to an exponential distribution, with average inter-arrival time of 50 msec. one second average 20 request averge.  means lambda = 20.

Since response time cannot exceed 10 ms, we need to calculate the possiblity,  If, within a 5 ms duration, we have 2 requests arriving, it would indeed exceed the 10 ms response time requirement. 

From https://homepage.divms.uiowa.edu/~mbognar/applets/exp-like.html we can get Possiblity is 9.5%,  it is not small since our server is run long time.   

Therefore, considering the potential risk of violating the Service Level Agreement and the associated penalties, we should reject this contract.

## Question2

### 1)

for one core, the peak floating-point performance in FLOP (Floating Point Operations Per Second) would be: 2 * 10^9 Hz * 2 = 4 * 10^9 FLOP/s

Since there are 16 cores in total, the peak performance of the entire chip would be: 16 cores * 4 * 10^9 FLOP/s = 64 * 10^9 FLOP/s = 64 GFLOP/s

### 2)

without memory bottleneck, the peak rate of floating-point operations is 64 GFLOP/s.

However one floating point is 4Bytes.  The memory bandwidth of the entire chip is 4GB/sec. Therefore one second chip can go throught 1G floating point.  

If we want to reach peak rate, we cannot move data throught memory, only calculate them on chip during this second.

what's more, all 16 cores need to run floating point operations, and use two floating point units simutaeiously. 

#### 3)

Peak floating-point operations per second (GFLOP/s) is a useful metric for characterizing the theoretical maximum floating-point performance of a processor.  This metric represents an ideal scenario that may not always be achievable in real-world applications.

The suitability of this metric depends on the type of workload or application:

- For highly parallel and compute-intensive tasks that fully utilize all available cores and floating-point units, the peak GFLOP/s can be a meaningful indicator of performance potential.
- However, many real-world applications may not fully saturate all cores and units simultaneously. Memory access patterns, data dependencies, and other factors can limit actual performance.
- In practice, sustained and achievable performance may be lower than the peak due to various bottlenecks, such as memory bandwidth limitations. --reference:  chatgpt.

## Question3

### 1)

Yes. It happens when a store instruction in Q1 and a speculative instruction also write the same address(may next loop).

### 2)

1. If the cache is hit, then LS can load data directly. 

2. If cache miss and data can be found in Q1, then LS can load data from Q1 because Q1 has not write back, but it will be.

3. If cache miss and Q1 miss, if we find it in Q2. It means data is related to uncommitted instruction. LS unit should check whether this speculative instruction is committed. It has two situation:

4. 1. If speculative instruction committed, then LS can load data from Q2. 
   2. If speculative instruction not committed, then LS needs to stall. 

## Question4

```cpp
double a[N], b[N], c[N], d[N], e[N];// N is a constant int i;
double u, v;
for(i = 0; i < N; i++) { 
  u = a[i] / b[i]; 
  v =  c[i]/ d[i];
  e[i]= u + v;
}
```

Reasons:

1. `u` and `v` can be computed independently in each iteration, so they don't have a data dependency.

## Question5

